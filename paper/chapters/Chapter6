\chapter{Resultados}
\label{Resultados}
\markboth{}{}


En este capítulo vamos a analizar la efectividad de los modelos propuestos.
El experimiento se realizó en CPU(Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz)
 
\section{Primera Red}

Ya tenemos los hiperparámetros óptimos del capítulo anterior, entonces vamos a definir la muestra de entrenamiento, validación y test. Crearemos 2 muestras, una amplia y una estrecha. En el cuadro 6.1 se define el ambiente de las muestras, y para generar la muestra se usa el algoritmo 5.1.


\begin{table}[!htbp]
\begin{center}
\caption{Hiperparametros de la Muestra}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Parametros & muestra amplia  &  muestra estrecha   \\ \hline
  & precio ratio($S_0$/K) & [0.4, 1.6] & [0.5, 1.5]   \\ \cline{2-4} 
 Entrada & Tiempo de madurez($\tau$) &  [0.2, 1.1] & [0.3, 0.95]   \\ \cline{2-4} 
  & volatilidad($\sigma$) &  [0.01, 1] & [0.02, 0.9]  \\ \cline{2-4} 
  & Tasa libre de riesgo($r$) &  [0.02, 0.1] & [0.03, 0.08] \\ \hline
 Salida & Precio de Call(c/K) &  (0, 0.9) & (0, 0.73) \\ \hline
\end{tabular}
\end{center}
\end{table}

Una vez obtenida la muestra, la entrada de la red será \{c/K, $S_0$/K, $r$, $\tau$\} y la salida \{$\sigma$\}. Vamos a entrenar la red durante 1000 épocas utilizando la muestra amplia y los hiperparámetros del obtenidos capítulo anterior. 

Una vez entrenada la red, en el Cuadro 6.2 y en las Figuras 6.1 y 6.2 se pueden observar los resultados.


\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_n.png}
    \caption{Predicción muestra amplia.}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_n.png}
    \caption{Predicción muestra estrecha.}
  \end{minipage}
\end{figure}

\begin{table}[!htbp]
\begin{center}
\caption{Error Red}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $3.21e(-4)$ & $6.09e(-3)$ & $9.30$ & 0.996031  \\ \hline
Muestra Estrecha & $1.47e(-4)$ &  $4.07e(-3)$ & $5.46$ & 0.997714  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


\section{Optimización}

Ya tenemos los hiperparámetros óptimos del capítulo anterior, entonces vamos a definir la muestra de entrenamiento, validación y test. Crearemos 2 muestras, una amplia y una estrecha. A diferencia de la muestra de la sección anterior, en esta se va a modificar utilizando la ecuación 5.1 del cápitulo anterior. En el cuadro 6.3 se define el ambiente de la muestra, y para generar las muestras se usa el algoritmo 5.1.

\begin{table}[!htbp]
\begin{center}
\caption{Hiperparametros de la Muestra}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Parametros & muestra amplia  &  muestra estrecha   \\ \hline
  & precio ratio($S_0$/K) & [0.4, 1.6] & [0.5, 1.5]   \\ \cline{2-4} 
 Entrada & Tiempo de madurez($\tau$) &  [0.2, 1.1] & [0.3, 0.95]   \\ \cline{2-4} 
  & volatilidad($\sigma$) &  [0.01, 1] & [0.02, 0.9]  \\ \cline{2-4} 
  & Tasa libre de riesgo($r$) &  [0.02, 0.1] & [0.03, 0.08] \\ \hline
 Salida & Precio de Call(log($\tilde{C}/{K}$)) &  [-16.12,-0.94] & [-16.12,-0.94] \\ \hline
\end{tabular}
\end{center}
\end{table}

Una vez obtenida la muestra, la entrada de la red será \{log($\tilde{C}/K$), $S_0$/K, $r$, $\tau$\} y la salida \{$\sigma$\}. Vamos a entrenar la red durante 1000 épocas.

Una vez entrenada la red, en el Cuadro 6.4 y en las Figuras 6.3 y 6.4 se pueden observar los resultados.


\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_log_mil.png}
    \caption{Predicción muestra amplia.}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_log_mil.png}
    \caption{Predicción muestra estrecha.}
  \end{minipage}
\end{figure}

\begin{table}[!htbp]
\begin{center}
\caption{Error Red Optimizada}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $6.24e(-8)$ & $1.92e(-4)$ & $0.059$ & 0.999999104  \\ \hline
Muestra Estrecha & $5.58e(-8)$ &  $ 1.84e(-4)$ & $0.062$ & 0.999999020  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


\subsection{Cambio en función de decrecimiento del Learning Rate}

Observando la Figura 5.1 podemos concluir que el entrenamiento de la red con un learning rate menor a $10^{-7}$ prácticamente no actualizaría los pesos, entonces si queremos hacer mas épocas en el entrenamiento de la red, con el algoritmo que usamos en la sección anterior tendríamos en la época 3000 un learning rate aproximado de $1.87e^{-17}$, y en la época 1000 el learning rate aproximado sería de $2.65e^{-8}$. Una posible solución a este problema es modificar los hiperparámetros óptimos aumentando el $base\_lr$, aumentar el $decay$, y aumentar el $epoch\_drop$, para que el learnig rate descienda mas lentamente. Otra solución sería cuando el learning rate sea menor a un umbral, aumentar el $base\_lr$. El umbral puede ser variable.

El algoritmo 6.1 muestra el método de decrecimiento de learning rate que utilizaremos:

\vspace{5mm}

\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\ResetInOut{output}
\Input{epoch}
\Output{lrate}
 i := 0\;
 step := floor((1+epoch)/10)\;
 lrate := 0.0005 * pow(0.9, step)\;
 \While{lrate $< 10^{-(6+i)}$}{
  lrate := 100*lrate\;
  i = i + 0.5\;
 }
 return\;
 \caption{Step Decay Modificado}
\end{algorithm}

\vspace{5mm}

La Figura 6.5 muestra la comparación entre el step decay usado anteriormente y el step decay modificado.

\begin{figure}[t!]
  \includegraphics[width=16cm, height=10cm]{imagenes/comparacion_step_1000}
  \caption{Step Decay Modificado}
\end{figure}

Las Figuras 6.6 y 6.7 muestan el learning rate resultante con los diferentes algoritmos.

\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{lr_1000.png}
    \caption{Learning Rate sobre 1000 epocas.}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{lr_3000.png}
    \caption{Learning Rate sobre 3000 epocas.}
  \end{minipage}
\end{figure}

Luego vamos a entrenar la red durante 3000 epocas usando step decay modificado. En las Figuras 6.8, 6.9, y en el Cuadro 6.5 se muestran los resultados.

\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_log_3mil.png}
    \caption{Predicción muestra amplia.}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_log_3mil.png}
    \caption{Predicción muestra estrecha.}
  \end{minipage}
\end{figure} 

\begin{table}[!htbp]
\begin{center}
\caption{Error Red Optimizada}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $4.67e(-8)$ & $1.66e(-4)$ & $0.0515$ & 0.999999329  \\ \hline
Muestra Estrecha & $4.02e(-8)$ &  $ 1.57e(-4)$ & $0.0526$ & 0.999999295  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


\section{Métodos Numéricos}


En el capítulo 4 vimos que hay casos en los que no se puede aplicar los métodos numéricos, exceptuando esos casos, vamos a analizar su precisión. Ademas en el capítulo 4 se vió que lo máximo que podemos aspirar es un error absoluto de 
$2^{-56}$. Ahora vamos a analizar si en la práctica, la tolerancia de los métodos corresponden con los resultados obtenidos de aplicar los mismos. En el método de Brent utilizamos el de la librería Scipy. \cite{Brentq}

En el cuadro 6.6 se muestran los resultados.

\begin{table}[!htbp]
\begin{center}
\caption{Error brent y Bisección}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Bisección  & $1.10e(-8)$ & $2.89e(-6)$ & $0.00469$ & 0.99999986  \\ \hline
Brent & $8.17e(-6)$ &  $ 9.18e(-5)$ & $0.35894$ & 0.99989551  \\ \hline
  
\end{tabular}
\end{center}
\end{table}

\subsection{Peso de la Volatilidad sobre el precio de la opción}




Observando el Cuadro 6.6, el error absoluto medio del método de bisección es $2.89e(-6)$ y de brent es
$ 9.18e(-5)$, siendo la tolerancia $2e(-56)$, esto es por el problema de presición y el impacto que tiene la volatilidad
sobre el precio de la opción utilizando la fórmuala de Black Scholes(definida en el sección 2.1.10). En la Figura 6.10, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes ratios, se puede observar que mientras más diferencia hay entre
$S_0$ y K la volatilidad tiene menos impacto sobre el precio en especial en los casos OTM y en las volatilidades cercanas a 0. Luego en la Figura 6.11, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes tasas de interés, se observa practicamente un desplazamiento.
Por último en la Figura 6.12, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes tiempos de madurez, se puede observa que mientras los contratos sean más largos la volatilidad tiene un
mayor impacto sobre el precio.

\begin{figure}[t!]
  \includegraphics[width=16cm, height=8cm]{imagenes/ratio_v_call}
  \caption{Volatilidad implícita vs precio call con distiontos ratios}
\end{figure}

\begin{figure}[t!]
  \includegraphics[width=16cm, height=6cm]{imagenes/interes_v_call}
  \caption{Volatilidad implícita vs precio call con distiontas tasas de interés}
\end{figure}

\begin{figure}[t!]
  \includegraphics[width=16cm, height=6cm]{imagenes/T_v_call}
  \caption{Volatilidad implícita vs precio call con distiontos tiempos de madurez}
\end{figure}




\vspace{5mm}


Ahora bien observando los gráficos podemos concluir que la volatilidad tiene menos impacto en los contratos cortos(en nuestro ambiente), en OTM y con volatilidades menores a 0.2, pero en la practica los casos con mas error son ITM
con $\Phi_1(\sigma)$ y $\Phi_2(\sigma)$ cercanos a 1, esto se debe a la densidad de puntos flotates \cite{IEEE}. Esto es la cantidad de números representables en un rango. El formato se escribe con un significando que tiene un bit entero implícito de valor 1 (excepto para los números especiales). Con los 52 bits de la mantisa, la precisión total es por lo tanto de 53 bits (es decir de $53log_{10}(2) \approx 15.955$ que se redondea a 16 dígitos decimales). El exponente de este formato está sesgado o desplazado en 1023 unidades, ya que como el máximo valor representado por 11 bits es 
$2^{11}-1=2047$, es la mitad de este rango la que representa exponentes positivos y la otra, exponentes negativos. Observar Figura 6.13.

\begin{figure}[t!]
  \includegraphics[width=16cm, height=3cm]{imagenes/precision}
  \caption{Estructura de un número en formato de coma flotante de doble precisión}
\end{figure}

\vspace{5mm}

Lo cual esto nos da que hay $2^{52}$ numeros entre $2^n$ y $2^{n+1}$ para todo n entero en [-1023, 1022].

Luego como el ancho de 11 bits del exponente permite la representación de números en el rango comprendido entre 
$2^{-1023}$ y $2^{1023}$ ($10^{-308}$ y $10^{308}$). Esto nos permite concluir q hay la misma cantidad de numeros representables entre $10^{-308}$ y $10^{-307}$ que en $0.1$ y $1$. Por lo tanto los $\Phi_1(\sigma)$ y $\Phi_2(\sigma)$
cercanos a 0 en OTM van a tener mas precisión aunque el peso de la volatilidad sobre el precio de la opción sea menor.

\section{Tiempo de Ejecución y Robustez}

Una vez entrenada la red (la busqueda de hiperpámetros fue 10.08 horas, la busqueda del algoritmo de learning rate fue 11.72 horas y entrenamiento de la red 3000 epocas fue 8.83 horas), vamos a observar el tiempo ejecución de evaluación de la misma sobre una muestra de 10000. Ademas el tiempo de ejecución de los métodos de brent y bisección sobre la misma muestra en una CPU(Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz).(CAMBIAR)

Tambien analizaremos su robustez, esto sería, si para todo elemento de la muesta el modelo genera una salida.

En el Cuadro 6.8 se observan el tiempo de ejecución y la Robustez. 

\begin{table}[!htbp]
\begin{center}
\caption{Robustez y Tiempo de Ejecución}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Red Neuronal & Método de Brent  &  Método de Bisección  \\ \hline
Tiempo de Ejecución(segundos)  & $7.34$  & $157.05$ & $318.31$   \\ \hline
Robustez & Si  &  No & No \\ \hline
  
\end{tabular}
\end{center}
\end{table}